[
  {
    "objectID": "GWRProj/DataPreprocessing.html",
    "href": "GWRProj/DataPreprocessing.html",
    "title": "IS415 - Project Data Preprocessing",
    "section": "",
    "text": "We will first need to Pre processed all the information that we need."
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#list-of-data",
    "href": "GWRProj/DataPreprocessing.html#list-of-data",
    "title": "IS415 - Project Data Preprocessing",
    "section": "List of Data",
    "text": "List of Data\nNote that this list is not exhaustive and if you find other point data you can add them as well.\n\n\n\nType\nName\nFormat\nSource\n\n\n\n\nAspatial\nResale Flat Price\n.csv\ndata.gov.sg\n\n\nGeospatial\nSingapore National Boundary\n.shp\ndata.gov.sg\n\n\nGeospatial\nMaster Plan 2019 Subzone Boundary (Web)\n.shp\nProf Kam\n\n\nGeospatial\nMRT Exit Point\n.shp\nLTA Data Mall\n\n\nGeospatial\nBus Stop Locations Aug 2023\n.shp\nLTA Data Mall\n\n\nGeospatial - Extracted\nChildcare Services\n.shp\nOneMap API\n\n\nGeospatial - Extracted\nEldercare Services\n.shp\nOneMap API\n\n\nGeospatial - Extracted\nHawker Centres\n.shp\nOneMap API\n\n\nGeospatial - Extracted\nKindergartens\n.shp\nOneMap API\n\n\nGeospatial - Extracted\nParks\n.shp\nOneMap API\n\n\nGeospatial - Extracted\nSupermarkets\n.kml\nOneMap API\n\n\nGeospatial - Extracted\nPrimary Schools\n.pdf\nMOE Website\n\n\nGeospatial - Selfsourced\nList of Shopping Mall\n.html\nWikipedia\n\n\nGeospatial - Selfsourced\nPharmacy\n.kml\nOneMap API\n\n\nGeospatial - Selfsourced\nIntegrated Screening Programme (ISP) Clinics\n.kml\nOneMap API\n\n\nGeospatial - Selfsourced\nLibraries\n.kml\nOneMap API\n\n\nGeospatial - Selfsourced\nTourist\n.kml\nOneMap API"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#importing-the-resale-data",
    "href": "GWRProj/DataPreprocessing.html#importing-the-resale-data",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Importing the Resale Data",
    "text": "Importing the Resale Data\n\nresale <- read_csv(\"data/aspatial/resale-flat-prices.csv\")\nglimpse(resale)\n\nTaking a look at the data we have noticed that the data set contains 11 columns with 148576 observations. They have the following columns: months, town, flat_type, block, street_name, storey_range, floor_area_sqm, flat_model, remaining_lease, resale_price. We are only interested in the following period from: 1st January 2021 to 31st December 2022 and January 2023 to February 2022.\n\nFiltering the Aspatial Data\nWe are making use of the filter function from the dplyr package to help us filter out the data. Find out more here. As there is more steps to be done on the aspatial data before it can be used for geographically weighted regression, we will split the data set into the period: 1st January 2021 to February 2022, for now.\n\nresale_flat_full <-  filter(resale,flat_type == \"4 ROOM\") %>% \n              filter(month >= \"2021-01\" & month <= \"2023-02\")\n\nOnce we have split it, we can make use of the unique function of Base R to ensure that all the data extracted out are correct. Find out more here.\n\nunique(resale_flat_full$flat_type)\n\n\nunique(resale_flat_full$month)\n\nFrom the result above, we can confirm that the data for data set is extracted correctly."
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#transforming-the-resale-data",
    "href": "GWRProj/DataPreprocessing.html#transforming-the-resale-data",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Transforming the Resale Data",
    "text": "Transforming the Resale Data\n\n\n\n\n\n\nImportant\n\n\n\nThe following steps are made with reference to: Take Home Exercise 3 done by: NOR AISYAH BINTE AJIT. Check out her work here.\n\n\nNow that we have correctly filter out the dataset that we wish to use, we are left with another problem. Lets have a look at our data as an example for me to better illustrate the problem.\n\nhead(resale_flat_full)\n\nIn our analysis, we are looking at the following key_factors:\n\nArea of the unit\nFloor level\nRemaining lease\nAge of the unit\n\nWith regards to the key factor. Notice how there are 4 key issues that we need to addressed:\n\nNo geospatial data: There is no geospatial data for us to plot out the points. This is worrying as the geospatial data is needed for us to perform geographically weighted regression. Fortunately, the data frame provided 2 columns that are critical in retrieving the coordinates of the flat, however it is found in 2 different columns: block, street_name. We would need to concatenate them together into to search for their coordinates.\nremaining_lease is recorded as a string: The remaining leases data is found as a string, when it should be an continuos variable. It is current written as a string currently, which will be treated as a categorical data instead, as such we would need to convert it into the correct format first.\nstorey_range is given as a range: In our dataset, the floor of the exact unique is not given, but rather a range is given this could be a huge potential issue as this would mean thatthe data will treated as a categorical data. We would need to convert it into the correct format first\nNo age: There is no age in our dataset, which would mean that we would need to solve this issue as well.\n\n\nRetrieving Postal Codes and Coordinates of the address\nAs mentioned before, one of the key issues that we would need to perform is to retrieve all the relevant data such as postal code and coordinates of the address that is needed for later analysis.\nThe steps are as followed:\n\nCombining Block and Street Name to form an address\nFiltering out Unique Address\nRetrieving coordinates from OneMap.API\nInspecting the Result and Fixing the Issues\n\n\nStep 1: Combining Block and Street Name to form an address\nIn this step, we will be combining the street_name and block to form an address.\nWe can make use of the paste() function from base R to concatenate the two data together. Find out more here.\nAfterwards, we will placed the data in a new columns called address in the dataframe by using the mutate() function from dplyr. Find out more about here.\n\nresale_flat_full <- resale_flat_full %>%\n  mutate(resale_flat_full, address = paste(block,street_name))\n\nhead(resale_flat_full)\n\n\n\nStep 2: Filtering out Unique Address.\nThis step is performed in order to minimize the amount of API Call that we need to perform. Furthermore, this also makes it easier for us to see which of the address will result in an error.\nWe will first get the unique address out first before sorting the data. This can be done with the sort() from base R. Find out more here.\n\nadd_list <- sort(unique(resale_flat_full$address))\n\n\n\nStep 3: Retrieiving Coordinates from OneMap API\nTo retrieve the coordinates from OneMap API, it will be easier to create a function to retrieve all the coordinate instead. To do so, lets take a deep dive into the OneMap API. Documentation can be found here. In this case, we will be making use of the OneMap API search API to retrieve the necessary coordinates.\nAccording to the documentation, the request requires the following.\n\nsearchVal: Keywords entered by user that is used to filter out the results.\nreturnGeom {Y/N}: Checks if user wants to return the geometry.\ngetAddrDetails {Y/N}: Checks if user wants to return address details for a point.\npageNum: Specifies the page to retrieve your search results from. This is optional (We will not be using this in this case)\n\nA provided example link would be something like this: https://developers.onemap.sg/commonapi/search?searchVal=revenue&returnGeom=Y&getAddrDetails=Y&pageNum=1\nThis will be the following response (Taken from OneMap API):\n\nWe are only interested in the LATITUDE and LONGITUDE data in this case.\nNow that we understand the API better, we will now create a function that will help us sort through all the data. The following code chunk below does a number of critical steps:\n\nWe will create a data frame called postal_coords that will store all the data frame.\nWe will make use of the GET() function from httr package to make a get request call. Find out more here.\nWe will create a data frame called new role to store all the coordinates\nWe also need to check the number of responses returned and append to the main data frame accordingly. This is because there are a few conditions to take note of\n\nThe number of results can be greater than one or none at all. (indicated by found in the JSON).\nThe results returned can have no postal code (which we will not consider as valid)\nWe will take the first result with a valid postal code as the correct coordinates.\n\nLastly, we will append the returned response (new_row) with the necessary fields to the main dataframe (postal_coords) using rbind() function of base R package. Find out more here.\n\nAll of this can be found in the code chunk below:\n\nget_coords <- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords <- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n\n    r <- GET('https://developers.onemap.sg/commonapi/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data <- fromJSON(rawToChar(r$content))\n    found <- data$found\n    res <- data$results\n    \n    # Create a new data frame for each address\n    new_row <- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal <- res$POSTAL \n      lat <- res$LATITUDE\n      lng <- res$LONGITUDE\n      new_row <- data.frame(address= i, postal = postal, latitude = lat, longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found > 1){\n      # Remove those with NIL as postal\n      res_sub <- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row <- data.frame(address= i, postal = NA, latitude = NA, longitude = NA)\n      }\n      \n      else{\n        top1 <- head(res_sub, n = 1)\n        postal <- top1$POSTAL \n        lat <- top1$LATITUDE\n        lng <- top1$LONGITUDE\n        new_row <- data.frame(address= i, postal = postal, latitude = lat, longitude = lng)\n      }\n    }\n\n    else {\n      new_row <- data.frame(address= i, postal = NA, latitude = NA, longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords <- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\nWith the function define we can call the function to generate out the data frame of the postal codes.\nPlease note that this function does take some time to run.\n\ncoords <- get_coords(add_list)\n\n\n\nStep 4: Inspecting the Result and Fixing the Issues\nRemember all the issues that we can face when making the api call, we would need to check to make sure that all the data is accounted for.\nWe can make use of the is.na() function to check which street address contains any NA values\n\ncoords[(is.na(coords$postal) | is.na(coords$latitude) | is.na(coords$longitude) | coords$postal==\"NIL\"), ]\n\nBased on the data frame above, we have noticed that there seems to be 2 address with no postal code\n\n215 CHOA CHU KANG\n216 CHOA CHU KANG\n\nWhen searching directly with OneMap API instead, we found that OneMap API classified them as the same building instead with the results being “BLK 216 AND 215 CHOA CHU KANG CENTRAL”. Furthermore a brief check on the website: property indicates the postal code as\n\n680215\n680216\n\nWe shall proceed with keeping them as the same as there is the latitude and longitude data.\n\n\n\nTransforming Remaining Lease\nIn this section, we will be transforming the remaining lease into an integer.\nFirst, we will split the remaining lease into years and months columns for calculation. To do so, we will make use of str_sub() function from tidyverse. Find out more here.\nwe will convert the string into an integer using the as.integer() function from base R. Find out more here.\n\nresale_flat_full <- resale_flat_full %>%\n  mutate(resale_flat_full, remaining_lease_yr = as.integer(str_sub(remaining_lease, 0, 2))) %>%\n  mutate(resale_flat_full, remaining_lease_mth = as.integer(str_sub(remaining_lease, 9, 11)))\n\nWe will then convert the NA values of the remaining_lease_mth columns into 0. We can make use of the is.na() function from base R. Find out more here.\nFollowed by changing the remaining_lease_yr into months.\nFinally, we can sum the two columns together with rowSums() function from base R. Find out more here.\n\nresale_flat_full$remaining_lease_mth[is.na(resale_flat_full$remaining_lease_mth)] <- 0\nresale_flat_full$remaining_lease_yr <- resale_flat_full$remaining_lease_yr * 12\nresale_flat_full <- resale_flat_full %>% \n  mutate(resale_flat_full, remaining_lease_mths = rowSums(resale_flat_full[, c(\"remaining_lease_yr\", \"remaining_lease_mth\")]))\n\n\n\nTransforming Storey Range\nCategorical variables require special attention in regression analysis because, unlike continuous variables, they cannot be entered into the regression equation just as they are. A method we can used to convert categorical variables into continuous variable is called “treatment” coding, or “dummy” coding. This method involve converting the categorical variable into a reference number.\nHowever, we must understand that storey range is an ordinal data, in other words, each categorical has an order, or in this case, low to high. Using a dummy variable might not make as much sense in this case. Hence, we will assign a higher value to higher floors. The reasoning behind it is that a higher floor offers more privacy, better security and lower noise pollution due to the high height.\nWe will first create a dataframe to store all the unique storey range and at the same time sort them. After they are sorted we will create a list of encoding based on the unique values then merging them to form a data frame\n\nstoreys <- sort(unique(resale_flat_full$storey_range))\nstorey_order <- 1:length(storeys)\nstorey_range_order <- data.frame(storeys, storey_order)\n\n\nhead(storey_range_order)\n\nFrom the above results, we can see that:\n\n01 TO 03 is assigned the value: 1\n04 TO 06 is assigned the value: 2\n07 TO 09 is assigned the value: 3\n10 TO 12 is assigned the value: 4\n13 TO 15 is assigned the value: 5\n16 TO 18 is assigned the value: 6\n\nHence, the storey range are in the correct order\n\n\nTransforming Age\nAge is one of the key factors that we are using in our analysis. However, there is no direct reference to age of the HDB. One method we can use is to infer the age of the building based on the remaining lease. It is well known that Singapore HDB are leased to us for 99 years as such we can calculate the age based on the difference between the total lease and remaining lease.\n\nresale_flat_full <- resale_flat_full %>% \n  mutate(resale_flat_full, age = 99 * 12 - resale_flat_full$remaining_lease_mths)\n\n\nhead(resale_flat_full)\n\n\n\nCombining all the data and storing as RDS\nWe will now combine all the relevant fields to a data frame using left_join() function of dplyr package. Find out more here.\n\nresale_flat_full <- left_join(resale_flat_full, storey_range_order, by= c(\"storey_range\" = \"storeys\"))\n\nrs_coords <- left_join(resale_flat_full, coords, by = c('address' = 'address'))\n\nWe can then store the data frame into a rds for use later.\n\nrs_coords_rds <- write_rds(rs_coords, \"data/aspatial/rds/rs_coords.rds\")"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#viewing-rds-data",
    "href": "GWRProj/DataPreprocessing.html#viewing-rds-data",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Viewing RDS Data",
    "text": "Viewing RDS Data\n\nReading RDS\nInstead of performing all the steps above again, once you save the data frame in a rds format, you can read the rds format again. Notice how the data frame is saved exactly as it is.\n\nrs_coords <- read_rds(\"data/aspatial/rds/rs_coords.rds\")\nhead(rs_coords)\n\n\n\nConverting to Sf Object\nSince the coordinate columns are Latitude & Longitude which are in decimal degrees, the projected CRS will be WGS84. We will need to assign them the respective EPSG code 4326 first before transforming it to 3414 which is the EPSG code for SVY21.\nWe will first use the st_as_sf() function of sf package to convert the data frame into sf object. Find out more here.\nFollowed by the st_transform() function of sf package to transform the coordinates of the sf object.\n\nrs_coords_sf <- st_as_sf(rs_coords,\n                    coords = c(\"longitude\", \n                               \"latitude\"),\n                    crs=4326) %>%\n  st_transform(crs = 3414)\n\nrs_coords_sf\n\n\n\nChecking for invalid geometries\nThe step below is not exactly mandatory, but it is good to check if the sf object is valid or not.\n\nlength(which(st_is_valid(rs_coords_sf) == FALSE))\n\n\n\nPlotting the HDB Resale points\n\ntmap_mode(\"view\")\ntm_shape(rs_coords_sf)+\n  tm_dots(col=\"blue\", size = 0.02)\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#extracting-the-data-from-onemap-api",
    "href": "GWRProj/DataPreprocessing.html#extracting-the-data-from-onemap-api",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Extracting the Data from OneMap API",
    "text": "Extracting the Data from OneMap API\nBefore we do a deep dive into examining the data, the first step that we need to do first is to extract out all the relevant data that we need. But first we need to see what OneMap API allows us to extract first.\nBefore we start off, I will first be introducing to you the onemapsgapi package that we will be using. You can learn more about the package here. You will need to sign up for an account so that they will generate a unique token for you to use. I have already pre-loaded my token into a variable called token.\n\nStep 1: Searching for Themes\nThe first step that we can do is to see what themes are available for us to use, with the code chunk below. In this case, we will be using the function search_themes() function to help us view all the available list. Find out more here.\n\n\n\n\n# Please replace token with the values of your own token.\navail_themes <- search_themes(token)\navail_themes\n\nAs you can see there seems to be a huge amount of themes available for us to use, which in this case I am interested only in a few namely, Eldercare Services, Childcare Services, Hawker Centres, Parks, Kindergartens. As you have noticed, there seems to be some themes that have repeated themselves, we would need to do a deep dive to find out more about what each theme contains.\n\n\nStep 2: A Closer Look at each theme\nOne ability of the search_themes() function is that you can make a query as well. This way there is no need to see all the other information that is not necessary for our evaluation.\nEldercare\n\navail_themes_elder <- search_themes(token, \"elder\")\navail_themes_elder\n\nThere is only one available theme relating to Eldercare, so this theme will be use. The query is eldercare\nChildcare\n\navail_themes_child <- search_themes(token, \"childcare\")\navail_themes_child\n\nThere is only one available theme relating to ChildCare, so this theme will be use. The query is childcare\nHawker Centres\n\navail_themes_hawker <- search_themes(token, \"hawker\")\navail_themes_hawker\n\nIn this case, there appears to be 3 different themes with the name “Hawker”. In this case, we can ignore the healthier_hawker_centres, as it category is in health rather than environment.\n\nhawkercentre_new <- get_theme(token, \"hawkercentre_new\")\nhawkercentre <- get_theme(token, \"hawkercentre\")\nhead(hawkercentre_new)\nhead(hawkercentre)\n\nIf we were to compare to 2 data frame, both data set has the same number of observations, with the only difference being that hawkercentre_new theme has more variables as compared to that of the hawkercentre. However, the difference in variables does seems to add value to the data frame at all and will be drop as those variables are not essential. Using either of the themes should have be fine, but I will be making use of the former for this exercise.\nThe query picked is hawkercentre_new\nParks\n\navail_themes_parks <- search_themes(token, \"parks\")\navail_themes_parks \n\nBased on the dataframe, above there seems to be a total of 25 different themes that matches the name “parks”, however this is due to the fact that it is the result also returns the results from the “National Parks Boards”. There are two themes that stands out the most here: “Parks” and “NParks Parks and Nature Reserve”. If we were to look into their category we found that the former belongs to recreation, while the latter belongs to environment. Seeing as we’re trying to relate the locational factors to the pricing of resale housing units, it makes more sense to go with the former!\nThe query chosen is nationalparks\nKindergarten\n\navail_themes_kindergarten <- search_themes(token, \"kinder\")\navail_themes_kindergarten\n\nThere is only one available theme relating to Kindergartens, so this theme will be use. The query is kindergartens\nClinic\n\navail_themes_clinic <- search_themes(token, \"health\")\navail_themes_clinic\n\nThere is only one available theme relating to Clinic, so this theme will be use. The query is moh_isp_clinics\nAnother theme of interest could also be Pharmacy, so this theme will be use. The query is registered_pharmacy\nTourist\n\navail_themes_tourist <- search_themes(token, \"tourism\")\navail_themes_kindergarten\n\nThere is only one available theme relating to Tourism, so this theme will be use. The query is tourism\nLibraries\n\navail_themes_libraries <- search_themes(token, \"libraries\")\navail_themes_libraries\n\nThere is only one available theme relating to Tourism, so this theme will be use. The query is libraries\nOthers\nOne thing to note is that we are no longer able to access some information that Megan has access to due to the update of the API such as the name of the primary school as well, which we will address in the other section.\n\n\nStep 3: Saving the Data into a data frame\nIn order to facilitate in the retrieving of themes, I have created the following function to aid me in retrieving the themes and saving them as a data frame.\nWe will be making use of the get_theme() function from the onemapsgapi package to retrieve the relevant and output it in a tibble frame. Read more here.\nAfterwards, we will convert the tibble to simple features dataframe. All the themes for this project use Lat and Lng as the latitude and longitude respectively, and our project coordinates system should be in the WGS84 system, aka ESPG code 4326.\nTo ensure that we can access the data again, we will save it into asf into a shapefile, which we can do with st_write() function.\n\nsave_theme_sf <- function(themename){\n  \n  themetibble <- get_theme(token, themename) %>%\n    select(c(\"NAME\", \"Lat\", \"Lng\") )\n  themesf <- st_as_sf(themetibble, coords=c(\"Lng\", \"Lat\"), crs=4326)\n  themename_file <- paste(\"data/extracted/\", themename, \".shp\", sep=\"\")\n  st_write(themesf, themename_file)\n} \n\n\nsave_theme_sf(\"eldercare\")\nsave_theme_sf(\"childcare\")\nsave_theme_sf(\"hawkercentre_new\")\nsave_theme_sf(\"nationalparks\")\nsave_theme_sf(\"kindergartens\")\nsave_theme_sf(\"moh_isp_clinics\")\nsave_theme_sf(\"registered_pharmacy\")\nsave_theme_sf(\"libraries\")\nsave_theme_sf(\"tourism\")"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#extracting-the-other-data",
    "href": "GWRProj/DataPreprocessing.html#extracting-the-other-data",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Extracting the Other Data",
    "text": "Extracting the Other Data\nNow that we have handled those data, one issue that we have face is that there is no data for most the Shopping Mall or Primary School.\nShopping Mall Data\nUnlike Megan’s Time where both Shopping Mall Data can be found in OneMap API, we need will need to make to do with the list from Wikipedia, which might not necessary be the most accurate, however, it appears to be the best list of data that we have.\nYou can find the link here. https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Singapore\nI have extracted the all the data from the wikipedia and clean it up manually.\n\nshopping_mall_list = c(\"100 AM\",\"313@Somerset\",\"Aperia\",\"Balestier Hill Shopping Centre\",\"Bugis Cube\",\"Bugis Junction\",\"Bugis+\",\"Capitol Piazza\",\"Cathay Cineleisure Orchard\",\"Clarke Quay Central\",\"The Centrepoint\",\"City Square Mall\",\"City Gate Mall\",\"CityLink Mall\",\"Duo\",\"Far East Plaza\",\"Funan\",\"Great World City\",\"HDB Hub\",\"Holland Village Shopping Mall\",\"ION Orchard\",\"Junction 8\",\"Knightsbridge\",\"Liat Towers\",\"Lucky Plaza\",\"Marina Bay Sands\",\"The Shoppes at Marina Bay Sands\",\"Marina Bay Link Mall\",\"Marina Square\",\"Millenia Walk\",\"Mustafa Shopping Centre\",\"Ngee Ann City\",\"Orchard Central\",\"Orchard Gateway\",\"Orchard Plaza\",\"Midpoint Orchard\",\"Palais Renaissance\",\"People's Park Centre\",\"People's Park Complex\",\"Plaza Singapura\",\"PoMo\",\"Raffles City\",\"Scotts Square\",\"Shaw House and Centre\",\"Sim Lim Square\",\"Singapore Shopping Centre\",\"The South Beach\",\"Square 2\",\"Sunshine Plaza\",\"Suntec City\",\"Tanglin Mall\",\"Tanjong Pagar Centre\",\"Tekka Centre\",\"The Adelphi\",\"The Paragon\",\"Tiong Bahru Plaza\",\"The Poiz\",\"Thomson Plaza\",\"United Square\",\"Thomson V\",\"Velocity@Novena Square\",\"Wheelock Place\",\"Wisma Atria\",\"Zhongshan Mall\",\"Bedok Mall\",\"Century Square\",\"Our Tampines Hub\",\"Changi City Point\",\"Downtown East\",\"Djitsun Mall Bedok\",\"Eastpoint Mall\",\"Jewel Changi Airport\",\"KINEX\",\"Katong Shopping Centre\",\"Katong Square\",\"Kallang Wave Mall\",\"Leisure Park Kallang\",\"i12 Katong\",\"Parkway Parade\",\"Paya Lebar Square\",\"Paya Lebar Quarter\",\"Roxy Square\",\"Singpost Centre\",\"Tampines 1\",\"Tampines Mall\",\"White Sands\",\"City Plaza\",\"Elias Mall\",\"Loyang Point\",\"888 Plaza\",\"Admiralty Place\",\"AMK Hub\",\"Canberra Plaza\",\"Causeway Point\",\"Woodlands Civic Centre\",\"Broadway Plaza\",\"Djitsun Mall\",\"Jubilee Square\",\"Junction 8\",\"Junction Nine\",\"Marsiling Mall\",\"Northpoint City\",\"Sembawang Shopping Centre\",\"Sun Plaza\",\"Vista Point\",\"Wisteria Mall\",\"Woodlands Mart\",\"Woodlands North Plaza\",\"Waterway Point\",\"Compass One\",\"Hougang Mall\",\"Heartland Mall\",\"NEX\",\"Buangkok Square\",\"Greenwich V\",\"Hougang 1\",\"Hougang Green Shopping Mall\",\"Hougang Rivercourt\",\"myVillage At Serangoon Garden\",\"Northshore Plaza\",\"Oasis Terraces\",\"Punggol Plaza\",\"Rivervale Mall\",\"Rivervale Plaza\",\"The Seletar Mall\",\"Upper Serangoon Shopping Centre\",\"Beauty World Centre\",\"Beauty World Plaza\",\"Bukit Panjang Plaza\",\"Bukit Timah Plaza\",\"Fajar Shopping Centre\",\"Greenridge Shopping Centre\",\"Hillion Mall\",\"HillV2\",\"Junction 10\",\"Keat Hong Shopping Centre\",\"Limbang Shopping Centre\",\"Lot One\",\"Rail Mall\",\"Sunshine Place\",\"Teck Whye Shopping Centre\",\"West Mall\",\"Yew Tee Point\",\"Yew Tee Square\",\"VivoCity\",\"HarbourFront Centre\",\"Alexandra Retail Centre\",\"321 Clementi\",\"The Clementi Mall\",\"IMM\",\"JCube\",\"Jem\",\"Westgate\",\"Jurong Point\",\"Pioneer Mall\",\"The Star Vista\",\"Alexandra Central\",\"Anchorpoint\",\"OD Mall\",\"Boon Lay Shopping Centre\",\"Grantral Mall\",\"Fairprice Hub\",\"Gek Poh Shopping Centre\",\"Rochester Mall\",\"Taman Jurong Shopping Centre\",\"West Coast Plaza\",\"Queensway Shopping Centre\")\n\nRemember the function that we have created to retrieve the hdb, we can make use of it here as well to find their coordinates.\nNote that this function does take some time to run.\n\nshop_coords <- get_coords(shopping_mall_list)\n\n\nshop_coords\n\nNow then we can check which Mall does not have the necessary data\n\nshop_coords[(is.na(shop_coords$postal) | is.na(shop_coords$latitude) | is.na(shop_coords$longitude) | shop_coords$postal==\"NIL\"), ]\n\nFrom the results above, we can see that there are 7 addresses that does not contain any information at all:\n\nClarke Quay Central\nCity Gate Mall\nHolland Village Shopping Mall\nMustafa Shopping Centre\nPoMo\nShaw House and Centre\nOD Mall\n\nI research deeper into the situation and found reverse search the malls to find their Postal Code, afterwards I will search out the name based on the One Map API and found the following:\n\nClarke Quay Central is called The Central\nCity Gate Mall is called City Gate\nHolland Village Shopping Mall is called Holland Road Shopping Centre\nMustafa Shopping Centre is called Mustafa Centre\nPoMO is called GR.ID\nShaw House and Centre is called Shaw Centre\nOD Mall is called The GrandStand\n\nI will append the names in the list below as it is easier:\n\nnew_shopping_mall_list = c(\"100 AM\",\"313@Somerset\",\"Aperia\",\"Balestier Hill Shopping Centre\",\"Bugis Cube\",\"Bugis Junction\",\"Bugis+\",\"Capitol Piazza\",\"Cathay Cineleisure Orchard\",\"The Central\",\"The Centrepoint\",\"City Square Mall\",\"City Gate\",\"CityLink Mall\",\"Duo\",\"Far East Plaza\",\"Funan\",\"Great World City\",\"HDB Hub\",\"Holland Road Shopping Centre\",\"ION Orchard\",\"Junction 8\",\"Knightsbridge\",\"Liat Towers\",\"Lucky Plaza\",\"Marina Bay Sands\",\"The Shoppes at Marina Bay Sands\",\"Marina Bay Link Mall\",\"Marina Square\",\"Millenia Walk\",\"Mustafa Centre\",\"Ngee Ann City\",\"Orchard Central\",\"Orchard Gateway\",\"Orchard Plaza\",\"Midpoint Orchard\",\"Palais Renaissance\",\"People's Park Centre\",\"People's Park Complex\",\"Plaza Singapura\",\"GR.ID\",\"Raffles City\",\"Scotts Square\",\"Shaw Centre\",\"Sim Lim Square\",\"Singapore Shopping Centre\",\"The South Beach\",\"Square 2\",\"Sunshine Plaza\",\"Suntec City\",\"Tanglin Mall\",\"Tanjong Pagar Centre\",\"Tekka Centre\",\"The Adelphi\",\"The Paragon\",\"Tiong Bahru Plaza\",\"The Poiz\",\"Thomson Plaza\",\"United Square\",\"Thomson V\",\"Velocity@Novena Square\",\"Wheelock Place\",\"Wisma Atria\",\"Zhongshan Mall\",\"Bedok Mall\",\"Century Square\",\"Our Tampines Hub\",\"Changi City Point\",\"Downtown East\",\"Djitsun Mall Bedok\",\"Eastpoint Mall\",\"Jewel Changi Airport\",\"KINEX\",\"Katong Shopping Centre\",\"Katong Square\",\"Kallang Wave Mall\",\"Leisure Park Kallang\",\"i12 Katong\",\"Parkway Parade\",\"Paya Lebar Square\",\"Paya Lebar Quarter\",\"Roxy Square\",\"Singpost Centre\",\"Tampines 1\",\"Tampines Mall\",\"White Sands\",\"City Plaza\",\"Elias Mall\",\"Loyang Point\",\"888 Plaza\",\"Admiralty Place\",\"AMK Hub\",\"Canberra Plaza\",\"Causeway Point\",\"Woodlands Civic Centre\",\"Broadway Plaza\",\"Djitsun Mall\",\"Jubilee Square\",\"Junction 8\",\"Junction Nine\",\"Marsiling Mall\",\"Northpoint City\",\"Sembawang Shopping Centre\",\"Sun Plaza\",\"Vista Point\",\"Wisteria Mall\",\"Woodlands Mart\",\"Woodlands North Plaza\",\"Waterway Point\",\"Compass One\",\"Hougang Mall\",\"Heartland Mall\",\"NEX\",\"Buangkok Square\",\"Greenwich V\",\"Hougang 1\",\"Hougang Green Shopping Mall\",\"Hougang Rivercourt\",\"myVillage At Serangoon Garden\",\"Northshore Plaza\",\"Oasis Terraces\",\"Punggol Plaza\",\"Rivervale Mall\",\"Rivervale Plaza\",\"The Seletar Mall\",\"Upper Serangoon Shopping Centre\",\"Beauty World Centre\",\"Beauty World Plaza\",\"Bukit Panjang Plaza\",\"Bukit Timah Plaza\",\"Fajar Shopping Centre\",\"Greenridge Shopping Centre\",\"Hillion Mall\",\"HillV2\",\"Junction 10\",\"Keat Hong Shopping Centre\",\"Limbang Shopping Centre\",\"Lot One\",\"Rail Mall\",\"Sunshine Place\",\"Teck Whye Shopping Centre\",\"West Mall\",\"Yew Tee Point\",\"Yew Tee Square\",\"VivoCity\",\"HarbourFront Centre\",\"Alexandra Retail Centre\",\"321 Clementi\",\"The Clementi Mall\",\"IMM\",\"JCube\",\"Jem\",\"Westgate\",\"Jurong Point\",\"Pioneer Mall\",\"The Star Vista\",\"Alexandra Central\",\"Anchorpoint\",\"The GrandStand\",\"Boon Lay Shopping Centre\",\"Grantral Mall\",\"Fairprice Hub\",\"Gek Poh Shopping Centre\",\"Rochester Mall\",\"Taman Jurong Shopping Centre\",\"West Coast Plaza\",\"Queensway Shopping Centre\")\n\n\nshop_coords_new <- get_coords(new_shopping_mall_list) \nshop_coords_new \n\nWe will check again to make sure that the data is correct\n\nshop_coords_new[(is.na(shop_coords_new$postal) | is.na(shop_coords_new$latitude) | is.na(shop_coords_new$longitude) | shop_coords_new$postal==\"NIL\"), ]\n\nSince we have confirm that the data is clean, we will just rename the columns to make it easier to understand.\n\nrename(shop_coords_new, \"name\" = \"address\")\n\nWe will save it as a shape file so that we can access it much more easily\n\nshopping_sf <- st_as_sf(shop_coords_new, coords=c(\"longitude\", \"latitude\"), crs=4326)\n\n\nst_write(shopping_sf, \"data/extracted/shopping_mall.shp\")\n\nPrimary School\nUnlike Megan’s Time where Primary School Data can be found in OneMap API and is found in Data.gov, we need will need to make to do with the list from MOE, which appears to be the best list of data that we have.\nYou can find the link here. https://www.moe.gov.sg/about-us/organisation-structure/sd/school-clusters\nI have extracted the all the data from the MOE and clean it up manually.\n\nprimary_sch_list = c(\"North Vista Primary School\",\"Palm View Primary School\",\"Rivervale Primary School\",\"Seng Kang Primary School\",\"Xinmin Primary School\",\"Ahmad Ibrahim Primary School\",\"Chongfu School\",\"Endeavour Primary School\",\"Jiemin Primary School\",\"Northland Primary School\",\"Northoaks Primary School\",\"Xishan Primary School\",\"Singapore Chinese Girls' School (Primary)\",\"Anchor Green Primary School\",\"Compassvale Primary School\",\"Edgefield Primary School\",\"Fernvale Primary School\",\"Hougang Primary School\",\"Yio Chu Kang Primary School\",\"Catholic High School (Primary)\",\"Anchor Green Primary School\",\"Compassvale Primary School\",\"Edgefield Primary School\",\"Fernvale Primary School\",\"Hougang Primary School\",\"Yio Chu Kang Primary School\",\"Catholic High School (Primary)\",\"Greendale Primary School\",\"Horizon Primary School\",\"Mee Toh School\",\"Montfort Junior School\",\"Nan Chiau Primary School\",\"North Spring Primary School\",\"Maris Stella High School (Primary)\",\"Admiralty Primary School\")\n\nprimary_sch_list_2=c(\"Evergreen Primary School\",\"Greenwood Primary School\",\"Marsiling Primary School\",\"Qihua Primary School\",\"Woodgrove Primary School\",\"Woodlands Ring Primary School\",\"Anderson Primary School\",\"Huamin Primary School\",\"Naval Base Primary School\",\"North View Primary School\",\"Peiying Primary School\",\"Sembawang Primary School\",\"Yishun Primary School\",\"CHIJ St Nicholas (Primary)\",\"Ang Mo Kio Primary School\",\"CHIJ Our Lady of Nativity\",\"Holy Innocents' Primary School\",\"Jing Shan Primary School\",\"Mayflower Primary School\",\"Punggol Primary School\",\"Blangah Rise Primary School\",\"Fairfield Methodist School (Primary)\",\"New Town Primary School\",\"Pei Tong Primary School\",\"Queenstown Primary School\",\"Anglo-Chinese Primary School\",\"CHIJ (Toa Payoh) Primary School\",\"First Toa Payoh Primary School\",\"Kheng Cheng School\",\"Marymount Convent School\",\"Pei Chun Public School\",\"Raffles Girls’ Primary School\",\"Alexandra Primary School\",\"Cantonment Primary School\",\"CHIJ (Kellock)\",\"Gan Eng Seng Primary School\",\"Hong Wen School\",\"Radin Mas Primary School\",\"River Valley Primary School\",\"Zhangde Primary School\",\"Anglo-Chinese Junior\",\"Bendemeer Primary School\",\"Farrer Park Primary School\",\"St. Andrew's Junior School\",\"St. Joseph's Institution Junior\",\"St. Margaret's Primary School\",\"Cedar Primary School\",\"CHIJ Our Lady of Good Counsel\",\"St Gabriel’s Primary School\",\"Xinghua Primary School\",\"Yangzheng Primary School\",\"Zhonghua Primary School\",\"Ai Tong School\",\"Kuo Chuan Presbyterian Primary School\",\"Teck Ghee Primary School\",\"Townsville Primary School\",\"Elias Park Primary School\",\"Meridian Primary School\",\"Northshore Primary School\",\"Punggol Cove Primary School\",\"Punggol Green Primary School\",\"Punggol View Primary School\",\"Valour Primary School\",\"Bedok Green Primary School\",\"Junyuan Primary School\",\"Poi Ching School\",\"Red Swastika School\",\"Temasek Primary School\",\"Yu Neng Primary School\",\"Angsana Primary School\",\"Chongzheng Primary School\",\"East Spring Primary School\",\"Fern Green Primary School\",\"Gongshang Primary School\",\"Sengkang Green Primary School\",\"Springdale Primary School\",\"Yumin Primary School\",\"Changkat Primary School\",\"Damai Primary School\",\"Kong Hwa School\",\"St Anthony’s Canossian Primary School\",\"Telok Kurau Primary School\",\"Canossa Catholic Primary School\",\"Fengshan Primary School\",\"Geylang Methodist School (Primary)\",\"Haig Girls’ School\",\"Paya Lebar Methodist Girls’ School (Primary)\",\"Tanjong Katong Primary School\",\"Casuarina Primary School\",\"Oasis Primary School\",\"Park View Primary School\",\"Pasir Ris Primary School\",\"St. Hilda’s Primary School\",\"Tampines North Primary School\",\"Tampines Primary School\",\"Waterway Primary School\",\"White Sands Primary School\",\"CHIJ (Katong) Primary\",\"Maha Bodhi School\",\"Ngee Ann Primary School\",\"Opera Estate Primary School\",\"St Stephen's Primary School\",\"Tao Nan School\",\"Clementi Primary School\",\"Henry Park Primary School\",\"Nan Hua Primary School\",\"Qifa Primary School\",\"Yuhua Primary School\",\"Chua Chu Kang Primary School\",\"Concord Primary School\",\"De La Salle School\",\"Nanyang Primary School\",\"South View Primary School\",\"Unity Primary School\",\"Corporation Primary School\",\"Frontier Primary School\",\"Jurong West Primary School\",\"Pioneer Primary School\",\"West Grove Primary School\",\"Xingnan Primary School\",\"Methodist Girls' School (Primary)\",\"Bukit View Primary School\",\"Dazhong Primary School\",\"Jurong Primary School\",\"Keming Primary School\",\"Lianhua Primary School\",\"St. Anthony's Primary School\",\"Beacon Primary School\",\"Greenridge Primary School\",\"Pei Hwa Presbyterian Primary School\",\"Teck Whye Primary School\",\"West View Primary School\",\"Zhenghua Primary School\",\"Boon Lay Garden Primary School\",\"Bukit Panjang Primary School\",\"CHIJ Our Lady Queen of Peace\",\"Kranji Primary School\",\"West Spring Primary School\",\"Westwood Primary School\",\"Yew Tee Primary School\",\"Bukit Timah Primary School\",\"Fuhua Primary School\",\"Lakeside Primary School\",\"Princess Elizabeth Primary School\",\"Rulang Primary School\",\"Shuqun Primary School\")\n\nWe will make use of the same function to get the list of Primary School Coordinates of Primary School\n\nprimary_sch_list_coor <- get_coords(primary_sch_list) \nprimary_sch_list_coor2 <- get_coords(primary_sch_list_2) \n\nOnce we Again we will check if both have any error\n\nprimary_sch_list_coor[(is.na(primary_sch_list_coor$postal) | is.na(primary_sch_list_coor$latitude) | is.na(primary_sch_list_coor$longitude) | primary_sch_list_coor$postal==\"NIL\"), ]\n\n\nprimary_sch_list_coor2[(is.na(primary_sch_list_coor2$postal) | is.na(primary_sch_list_coor2$latitude) | is.na(primary_sch_list_coor2$longitude) | primary_sch_list_coor2$postal==\"NIL\"), ]\n\nFrom the results above, we can see that there are 7 addresses that does not contain any information at all:\n\nMaris Stella High School (Primary)\nCHIJ St Nicholas (Primary)\nCHIJ (Toa Payoh) Primary School\nSt Gabriel’s Primary School\nSt Anthony’s Canossian Primary School\nSt. Hilda’s Primary School\nSt Stephen’s Primary School\n\nI research deeper into the situation and found reverse search the malls to find their Postal Code, afterwards I will search out the name based on the One Map API and found the following:\n\nMaris Stella High School (Primary) is called Maris Stella High School\nCHIJ St Nicholas (Primary) is called CHIJ St Nicholas\nCHIJ (Toa Payoh) Primary School is called CHIJ Primary (Toa Payoh)\nSt Gabriel’s Primary School is called Saint Gabriel Primary School\nSt Anthony’s Canossian Primary School is called Saint Anthony Canossian Primary School\nSt. Hilda’s Primary School is called Saint Hilda Primary School\nSt Stephen’s Primary School is called Saint Stephen School\n\nWe will just replace it in the names in the list again.\n\nprimary_sch_list = c(\"North Vista Primary School\",\"Palm View Primary School\",\"Rivervale Primary School\",\"Seng Kang Primary School\",\"Xinmin Primary School\",\"Ahmad Ibrahim Primary School\",\"Chongfu School\",\"Endeavour Primary School\",\"Jiemin Primary School\",\"Northland Primary School\",\"Northoaks Primary School\",\"Xishan Primary School\",\"Singapore Chinese Girls' School (Primary)\",\"Anchor Green Primary School\",\"Compassvale Primary School\",\"Edgefield Primary School\",\"Fernvale Primary School\",\"Hougang Primary School\",\"Yio Chu Kang Primary School\",\"Catholic High School (Primary)\",\"Anchor Green Primary School\",\"Compassvale Primary School\",\"Edgefield Primary School\",\"Fernvale Primary School\",\"Hougang Primary School\",\"Yio Chu Kang Primary School\",\"Catholic High School (Primary)\",\"Greendale Primary School\",\"Horizon Primary School\",\"Mee Toh School\",\"Montfort Junior School\",\"Nan Chiau Primary School\",\"North Spring Primary School\",\"Maris Stella High School\",\"Admiralty Primary School\")\n\nprimary_sch_list_2=c(\"Evergreen Primary School\",\"Greenwood Primary School\",\"Marsiling Primary School\",\"Qihua Primary School\",\"Woodgrove Primary School\",\"Woodlands Ring Primary School\",\"Anderson Primary School\",\"Huamin Primary School\",\"Naval Base Primary School\",\"North View Primary School\",\"Peiying Primary School\",\"Sembawang Primary School\",\"Yishun Primary School\",\"CHIJ St Nicholas\",\"Ang Mo Kio Primary School\",\"CHIJ Our Lady of Nativity\",\"Holy Innocents' Primary School\",\"Jing Shan Primary School\",\"Mayflower Primary School\",\"Punggol Primary School\",\"Blangah Rise Primary School\",\"Fairfield Methodist School (Primary)\",\"New Town Primary School\",\"Pei Tong Primary School\",\"Queenstown Primary School\",\"Anglo-Chinese Primary School\",\"CHIJ Primary (Toa Payoh)\",\"First Toa Payoh Primary School\",\"Kheng Cheng School\",\"Marymount Convent School\",\"Pei Chun Public School\",\"Raffles Girls’ Primary School\",\"Alexandra Primary School\",\"Cantonment Primary School\",\"CHIJ (Kellock)\",\"Gan Eng Seng Primary School\",\"Hong Wen School\",\"Radin Mas Primary School\",\"River Valley Primary School\",\"Zhangde Primary School\",\"Anglo-Chinese Junior\",\"Bendemeer Primary School\",\"Farrer Park Primary School\",\"St. Andrew's Junior School\",\"St. Joseph's Institution Junior\",\"St. Margaret's Primary School\",\"Cedar Primary School\",\"CHIJ Our Lady of Good Counsel\",\"Saint Gabriel Primary School\",\"Xinghua Primary School\",\"Yangzheng Primary School\",\"Zhonghua Primary School\",\"Ai Tong School\",\"Kuo Chuan Presbyterian Primary School\",\"Teck Ghee Primary School\",\"Townsville Primary School\",\"Elias Park Primary School\",\"Meridian Primary School\",\"Northshore Primary School\",\"Punggol Cove Primary School\",\"Punggol Green Primary School\",\"Punggol View Primary School\",\"Valour Primary School\",\"Bedok Green Primary School\",\"Junyuan Primary School\",\"Poi Ching School\",\"Red Swastika School\",\"Temasek Primary School\",\"Yu Neng Primary School\",\"Angsana Primary School\",\"Chongzheng Primary School\",\"East Spring Primary School\",\"Fern Green Primary School\",\"Gongshang Primary School\",\"Sengkang Green Primary School\",\"Springdale Primary School\",\"Yumin Primary School\",\"Changkat Primary School\",\"Damai Primary School\",\"Kong Hwa School\",\"Saint Anthony Canossian Primary School\",\"Telok Kurau Primary School\",\"Canossa Catholic Primary School\",\"Fengshan Primary School\",\"Geylang Methodist School (Primary)\",\"Haig Girls’ School\",\"Paya Lebar Methodist Girls’ School (Primary)\",\"Tanjong Katong Primary School\",\"Casuarina Primary School\",\"Oasis Primary School\",\"Park View Primary School\",\"Pasir Ris Primary School\",\"Saint Hilda Primary School\",\"Tampines North Primary School\",\"Tampines Primary School\",\"Waterway Primary School\",\"White Sands Primary School\",\"CHIJ (Katong) Primary\",\"Maha Bodhi School\",\"Ngee Ann Primary School\",\"Opera Estate Primary School\",\"Saint Stephen School\",\"Tao Nan School\",\"Clementi Primary School\",\"Henry Park Primary School\",\"Nan Hua Primary School\",\"Qifa Primary School\",\"Yuhua Primary School\",\"Chua Chu Kang Primary School\",\"Concord Primary School\",\"De La Salle School\",\"Nanyang Primary School\",\"South View Primary School\",\"Unity Primary School\",\"Corporation Primary School\",\"Frontier Primary School\",\"Jurong West Primary School\",\"Pioneer Primary School\",\"West Grove Primary School\",\"Xingnan Primary School\",\"Methodist Girls' School (Primary)\",\"Bukit View Primary School\",\"Dazhong Primary School\",\"Jurong Primary School\",\"Keming Primary School\",\"Lianhua Primary School\",\"St Anthony's Primary School\",\"Beacon Primary School\",\"Greenridge Primary School\",\"Pei Hwa Presbyterian Primary School\",\"Teck Whye Primary School\",\"West View Primary School\",\"Zhenghua Primary School\",\"Boon Lay Garden Primary School\",\"Bukit Panjang Primary School\",\"CHIJ Our Lady Queen of Peace\",\"Kranji Primary School\",\"West Spring Primary School\",\"Westwood Primary School\",\"Yew Tee Primary School\",\"Bukit Timah Primary School\",\"Fuhua Primary School\",\"Lakeside Primary School\",\"Princess Elizabeth Primary School\",\"Rulang Primary School\",\"Shuqun Primary School\")\n\n\nprimary_sch_list_coor <- get_coords(primary_sch_list) \nprimary_sch_list_coor2 <- get_coords(primary_sch_list_2) \n\nWe will need to check again to make sure that there is no missing data\n\nprimary_sch_list_coor[(is.na(primary_sch_list_coor$postal) | is.na(primary_sch_list_coor$latitude) | is.na(primary_sch_list_coor$longitude) | primary_sch_list_coor$postal==\"NIL\"), ]\n\n\nprimary_sch_list_coor2[(is.na(primary_sch_list_coor2$postal) | is.na(primary_sch_list_coor2$latitude) | is.na(primary_sch_list_coor2$longitude) | primary_sch_list_coor2$postal==\"NIL\"), ]\n\nSince we have confirm that the data is clean, we will just rename the columns to make it easier to understand.\n\nprimary_sch_list_coor_full <- rbind(primary_sch_list_coor, primary_sch_list_coor2)\n\n\nrename(primary_sch_list_coor_full, \"name\" = \"address\")\n\nWe can write it into a shape file for us to access everything again.\n\nprimary_sch_sf <- st_as_sf(primary_sch_list_coor_full, coords=c(\"longitude\", \"latitude\"), crs=4326)\n\n\nst_write(primary_sch_sf, \"data/extracted/primary_school.shp\")\n\nGood Primary School\nEducation and academic institutions are an especially important locational factors for families with children, or expect to have children. Since it has already been proven that distance affects priority admission, the number of good Primary School around the area is important as well. For this analysis, our focus will be on the primary-school level of education, we would need to understand what is defined as “Good Primary School”. MOE does not released a list of Primary Schools ranked based on their result as such, there is now way to determine how the Primary School are actually ranked.\nOne possible example of the ranking would be the schlah’s Primary School Rankings from the 2020. Although the list is a bit dated, It does offer a transparent method on how they determined what is considered a “Good Primary School” primarily through:\n\nPopularity in Primary 1 (P1) Registration: 20%\nGifted Education Programme (GEP): 20%\nSpecial Assistance Plan (SAP): 15%\nAchievements in the Singapore Youth Festival Arts Presentation: 15%\nRepresentation in the Singapore National School Games: 15%\nSingapore Uniformed Groups Unit Recognition: 15%\n\nFor my analysis, I will consider the Top 10 Primary School as Good Primary School:\n\n\ngood_primary_school <- c(\"Nanyang Primary School\",\"Tao Nan School\",\"Catholic High School (Primary)\",\"Nan Hua Primary School\",\"Saint Hilda Primary School\",\"Henry Park Primary School\",\"Anglo-Chinese Primary School\",\"Raffles Girls’ Primary School\",\"Pei Hwa Presbyterian Primary School\",\"CHIJ St Nicholas\")\n\nWe will once again make use of the OneMap API to get the theme\n\ngood_primary_school_coor <- get_coords(good_primary_school) \n\nWe will need to check again to make sure that there is no missing data.\n\ngood_primary_school_coor[(is.na(good_primary_school_coor$postal) | is.na(good_primary_school_coor$latitude) | is.na(good_primary_school_coor$longitude) | good_primary_school_coor$postal==\"NIL\"), ]\n\nSince we have confirm that the data is cleaned we can save it as a shape file to reference again.\n\nrename(good_primary_school_coor, \"name\" = \"address\")\n\n\ngood_primary_sch_sf <- st_as_sf(good_primary_school_coor, coords=c(\"longitude\", \"latitude\"), crs=4326)\n\n\nst_write(good_primary_sch_sf, \"data/extracted/good_primary_school.shp\")\n\nCBD\nLastly, we need to factor in the proximity to the Central Business District - in the Downtown Core. It’s located in the southwest of Singapore. As such, let’s take the coordinates of Downtown Core to be the coordinates of the CBD, we will store it as a CBD as well.\n\nlat <- 1.287953\nlng <- 103.851784\n\ncbd_sf <- data.frame(lat, lng) %>%\n  st_as_sf(coords = c(\"lng\", \"lat\"), crs=4326)\n\nst_write(cbd_sf, \"data/extracted/cbd.shp\")"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#importing-the-resale-data-1",
    "href": "GWRProj/DataPreprocessing.html#importing-the-resale-data-1",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Importing the Resale Data",
    "text": "Importing the Resale Data\n\nresale_flat_full <- read_csv(\"data/aspatial/resale-flat-prices-from-jan-2017-onwards.csv\")\nglimpse(resale_flat_full)\n\nTaking a look at the data we have noticed that the data set contains 11 columns with 23656 observations. Depending on when your data is loaded, it can have more observations. They have the following columns: months, town, flat_type, block, street_name, storey_range, floor_area_sqm, flat_model, remaining_lease, resale_price."
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#retrieving-postal-codes-and-coordinates-of-the-address-1",
    "href": "GWRProj/DataPreprocessing.html#retrieving-postal-codes-and-coordinates-of-the-address-1",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Retrieving Postal Codes and Coordinates of the address",
    "text": "Retrieving Postal Codes and Coordinates of the address\nAs mentioned before, one of the key issues that we would need to perform is to retrieve all the relevant data such as postal code and coordinates of the address that is needed for later analysis.\nThe steps are as followed:\n\nCombining Block and Street Name to form an address\nFiltering out Unique Address\nRetrieving coordinates from OneMap.API\nInspecting the Result and Fixing the Issues\n\n\nStep 1: Combining Block and Street Name to form an address\nIn this step, we will be combining the street_name and block to form an address.\nWe can make use of the paste() function from base R to concatenate the two data together. Find out more here.\nAfterwards, we will placed the data in a new columns called address in the dataframe by using the mutate() function from dplyr. Find out more about here.\n\nresale_flat_full <- resale_flat_full %>%\n  mutate(resale_flat_full, address = paste(block,street_name))\n\nhead(resale_flat_full)\n\n\n\nStep 2: Filtering out Unique Address.\nThis step is performed in order to minimize the amount of API Call that we need to perform. Furthermore, this also makes it easier for us to see which of the address will result in an error.\nWe will first get the unique address out first before sorting the data. This can be done with the sort() from base R. Find out more here.\n\nadd_list <- sort(unique(resale_flat_full$address))\n\n\n\nStep 3: Retrieiving Coordinates from OneMap API\nTo retrieve the coordinates from OneMap API, it will be easier to create a function to retrieve all the coordinate instead. To do so, lets take a deep dive into the OneMap API. Documentation can be found here. In this case, we will be making use of the OneMap API search API to retrieve the necessary coordinates.\nAccording to the documentation, the request requires the following.\n\nsearchVal: Keywords entered by user that is used to filter out the results.\nreturnGeom {Y/N}: Checks if user wants to return the geometry.\ngetAddrDetails {Y/N}: Checks if user wants to return address details for a point.\npageNum: Specifies the page to retrieve your search results from. This is optional (We will not be using this in this case)\n\nA provided example link would be something like this: https://developers.onemap.sg/commonapi/search?searchVal=revenue&returnGeom=Y&getAddrDetails=Y&pageNum=1\nWe are only interested in the LATITUDE and LONGITUDE data in this case.\nNow that we understand the API better, we will now create a function that will help us sort through all the data. The following code chunk below does a number of critical steps:\n\nWe will create a data frame called postal_coords that will store all the data frame.\nWe will make use of the GET() function from httr package to make a get request call. Find out more here.\nWe will create a data frame called new role to store all the coordinates\nWe also need to check the number of responses returned and append to the main data frame accordingly. This is because there are a few conditions to take note of\n\nThe number of results can be greater than one or none at all. (indicated by found in the JSON).\nThe results returned can have no postal code (which we will not consider as valid)\nWe will take the first result with a valid postal code as the correct coordinates.\n\nLastly, we will append the returned response (new_row) with the necessary fields to the main dataframe (postal_coords) using rbind() function of base R package. Find out more here.\n\nAll of this can be found in the code chunk below:\n\nget_coords <- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords <- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n\n    r <- GET('https://developers.onemap.sg/commonapi/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data <- fromJSON(rawToChar(r$content))\n    found <- data$found\n    res <- data$results\n    \n    # Create a new data frame for each address\n    new_row <- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal <- res$POSTAL \n      lat <- res$LATITUDE\n      lng <- res$LONGITUDE\n      new_row <- data.frame(address= i, postal = postal, latitude = lat, longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found > 1){\n      # Remove those with NIL as postal\n      res_sub <- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row <- data.frame(address= i, postal = NA, latitude = NA, longitude = NA)\n      }\n      \n      else{\n        top1 <- head(res_sub, n = 1)\n        postal <- top1$POSTAL \n        lat <- top1$LATITUDE\n        lng <- top1$LONGITUDE\n        new_row <- data.frame(address= i, postal = postal, latitude = lat, longitude = lng)\n      }\n    }\n\n    else {\n      new_row <- data.frame(address= i, postal = NA, latitude = NA, longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords <- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\nWith the function define we can call the function to generate out the data frame of the postal codes.\nPlease note that this function does take some time to run.\n\ncoords <- get_coords(add_list)\n\n\n\nStep 4: Inspecting the Result and Fixing the Issues\nRemember all the issues that we can face when making the api call, we would need to check to make sure that all the data is accounted for.\nWe can make use of the is.na() function to check which street address contains any NA values\n\ncoords[(is.na(coords$postal) | is.na(coords$latitude) | is.na(coords$longitude) | coords$postal==\"NIL\"), ]\n\n\n\n\n\n\n\nNote\n\n\n\nThe issues can be different so make sure to correct them based on your own observations.\n\n\nBased on the data frame above, we have noticed that there seems to be 2 address with no postal code\n\n215 CHOA CHU KANG\n216 CHOA CHU KANG\n\nWhen searching directly with OneMap API instead, we found that OneMap API classified them as the same building instead with the results being “BLK 216 AND 215 CHOA CHU KANG CENTRAL”. Furthermore a brief check on the website: property indicates the postal code as\n\n680215\n680216\n\nWe shall proceed with keeping them as the same as there is the latitude and longitude data."
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#transforming-remaining-lease-1",
    "href": "GWRProj/DataPreprocessing.html#transforming-remaining-lease-1",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Transforming Remaining Lease",
    "text": "Transforming Remaining Lease\nIn this section, we will be transforming the remaining lease into an integer.\nFirst, we will split the remaining lease into years and months columns for calculation. To do so, we will make use of str_sub() function from tidyverse. Find out more here.\nwe will convert the string into an integer using the as.integer() function from base R. Find out more here.\n\nresale_flat_full <- resale_flat_full %>%\n  mutate(resale_flat_full, remaining_lease_yr = as.integer(str_sub(remaining_lease, 0, 2))) %>%\n  mutate(resale_flat_full, remaining_lease_mth = as.integer(str_sub(remaining_lease, 9, 11)))\n\nWe will then convert the NA values of the remaining_lease_mth columns into 0. We can make use of the is.na() function from base R. Find out more here.\nFollowed by changing the remaining_lease_yr into months.\nFinally, we can sum the two columns together with rowSums() function from base R. Find out more here.\n\nresale_flat_full$remaining_lease_mth[is.na(resale_flat_full$remaining_lease_mth)] <- 0\nresale_flat_full$remaining_lease_yr <- resale_flat_full$remaining_lease_yr * 12\nresale_flat_full <- resale_flat_full %>% \n  mutate(resale_flat_full, remaining_lease_mths = rowSums(resale_flat_full[, c(\"remaining_lease_yr\", \"remaining_lease_mth\")]))"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#transforming-storey-range-1",
    "href": "GWRProj/DataPreprocessing.html#transforming-storey-range-1",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Transforming Storey Range",
    "text": "Transforming Storey Range\nCategorical variables require special attention in regression analysis because, unlike continuous variables, they cannot be entered into the regression equation just as they are. A method we can used to convert categorical variables into continuous variable is called “treatment” coding, or “dummy” coding. This method involve converting the categorical variable into a reference number.\nHowever, we must understand that storey range is an ordinal data, in other words, each categorical has an order, or in this case, low to high. Using a dummy variable might not make as much sense in this case. Hence, we will assign a higher value to higher floors. The reasoning behind it is that a higher floor offers more privacy, better security and lower noise pollution due to the high height.\nWe will first create a dataframe to store all the unique storey range and at the same time sort them. After they are sorted we will create a list of encoding based on the unique values then merging them to form a data frame\n\nstoreys <- sort(unique(resale_flat_full$storey_range))\nstorey_order <- 1:length(storeys)\nstorey_range_order <- data.frame(storeys, storey_order)\n\n\nhead(storey_range_order)\n\nFrom the above results, we can see that:\n\n01 TO 03 is assigned the value: 1\n04 TO 06 is assigned the value: 2\n07 TO 09 is assigned the value: 3\n10 TO 12 is assigned the value: 4\n13 TO 15 is assigned the value: 5\n16 TO 18 is assigned the value: 6\n\nHence, the storey range are in the correct order"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#transforming-age-1",
    "href": "GWRProj/DataPreprocessing.html#transforming-age-1",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Transforming Age",
    "text": "Transforming Age\nAge is one of the key factors that we are using in our analysis. However, there is no direct reference to age of the HDB. One method we can use is to infer the age of the building based on the remaining lease. It is well known that Singapore HDB are leased to us for 99 years as such we can calculate the age based on the difference between the total lease and remaining lease.\n\nresale_flat_full <- resale_flat_full %>% \n  mutate(resale_flat_full, age = 99 * 12 - resale_flat_full$remaining_lease_mths)\n\n\nhead(resale_flat_full)\n\n\nresale_flat_full <- left_join(resale_flat_full, storey_range_order, by= c(\"storey_range\" = \"storeys\"))\n\nrs_coords <- left_join(resale_flat_full, coords, by = c('address' = 'address'))\n\n\nrs_coords_rds <- write_rds(rs_coords, \"data/rds/rs_coords.rds\")\n\n\nrs_coords <- read_rds(\"data/rds/rs_coords.rds\")\n\n\nrs_coords_sf <- st_as_sf(rs_coords,\n                    coords = c(\"longitude\", \n                               \"latitude\"),\n                    crs=4326) %>%\n  st_transform(crs = 3414)"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#calculating-proximity",
    "href": "GWRProj/DataPreprocessing.html#calculating-proximity",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Calculating Proximity",
    "text": "Calculating Proximity\nOne of the things we need to find is the proximity to particular facilities as one of factors.\nMegan has kindly provided the function for us to use above. First, she use compute with st_distance(), to compute the proximity to the facility and find the closest facility (shortest distance) with the rowMins() function of our matrixStats package. The values will be appended to the data frame as a new column.\n\nproximity <- function(df1, df2, varname) {\n  dist_matrix <- st_distance(df1, df2) %>%\n    units::drop_units()\n  df1[,varname] <- rowMins(dist_matrix)\n  return(df1)\n}\n\n\nrs_coords_sf <- \n  # the columns will be truncated later on when viewing \n  # so we're limiting ourselves to two-character columns for ease of viewing between\n  proximity(rs_coords_sf, CBD_3414, \"PROX_CBD\") %>%\n  proximity(., childcare3414, \"PROX_CHILDCARE\") %>%\n  proximity(., eldercare3414, \"PROX_ELDERCARE\") %>%\n  proximity(., hawker_centre3414, \"PROX_HAWKER\") %>%\n  proximity(., mrts_3414 , \"PROX_MRT\") %>%\n  proximity(., parks3414, \"PROX_PARK\") %>%\n  proximity(., top_primary_sch_sf_3414, \"PROX_TOPPRISCH\") %>%\n  proximity(., shopping_mall_sf_3414, \"PROX_MALL\") %>%\n  proximity(., supermarket_sf_3414, \"PROX_SPRMKT\") %>%\n  proximity(., isp_clinics3414, \"PROX_CLINIC\") %>%\n  proximity(., registered_pharmacy_3414, \"PROX_PHARMACY\") %>%\n  proximity(., tourism3414, \"PROX_TOURISM\") %>%\n  proximity(., libraries3414, \"PROX_LIBRARY\")"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#facility-count-within-radius",
    "href": "GWRProj/DataPreprocessing.html#facility-count-within-radius",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Facility Count Within Radius",
    "text": "Facility Count Within Radius\nOther than proximity, which calculates the shortest distance, we also want to find the number of facilities within a particular radius as another factors.\nMegan has kindly provided the function for us to use above. First, she use st_distance() to compute the distance between the flats and the desired facilities, and then sum up the observations with rowSums(). The values will be appended to the data frame as a new column.\n\nnum_radius <- function(df1, df2, varname, radius) {\n  dist_matrix <- st_distance(df1, df2) %>%\n    drop_units() %>%\n    as.data.frame()\n  df1[,varname] <- rowSums(dist_matrix <= radius)\n  return(df1)\n}\n\n\nrs_coords_sf <-\n  num_radius(rs_coords_sf, kindergarten3414, \"NUM_KNDRGTN\", 350) %>%\n  num_radius(., childcare3414, \"NUM_CHILDCARE\", 350) %>%\n  num_radius(., bus_stop_3414, \"NUM_BUS_STOP\", 350) %>%\n  num_radius(., isp_clinics3414, \"NUM_ISP_CLIN\", 350) %>%\n  num_radius(., registered_pharmacy_3414, \"NUM_REGISTERED_PHARM\", 350) %>%\n    num_radius(., libraries3414, \"NUM_LIBRARIES\", 350) %>%\n  num_radius(., primary_sch_sf_3414, \"NUM_PRI_SCH\", 1000)"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#saving-the-data-into-rds",
    "href": "GWRProj/DataPreprocessing.html#saving-the-data-into-rds",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Saving the Data into RDS",
    "text": "Saving the Data into RDS\nWell we do not really need all the columns, and we also do not want to read all the files again, we can save it as a rds format so that we can access it again.\nBefore we save it into RDS, we can clean up columns that we do not really need.\n\nrs_coords_full_rds <- write_rds(rs_coords_sf, \"data/rds/rs_coords_full.rds\")\n\nYou have now pre processed the data and you can now load the data into the Shiny application"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#generating-the-new-geographically-weighted-linear-model",
    "href": "GWRProj/DataPreprocessing.html#generating-the-new-geographically-weighted-linear-model",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Generating the new GeoGraphically Weighted Linear Model",
    "text": "Generating the new GeoGraphically Weighted Linear Model\n\nLoading the Data\n\nrs_coords_full_rds <- read_rds(\"data/rds/rs_coords_full.rds\")\n\n\n\nFiltering the Data\n\nstart_date <- \"2021-01\"\nend_date <- \"2022-12\"\nfilter_flat_type <- \"4 ROOM\"\nresale_flat_full_nogeo <-  filter(rs_coords_full_rds, flat_type == filter_flat_type) %>% \n        filter(month >= start_date & month <= end_date) %>%\n        select(2, 7, 11, 15:17, 19:38) %>%\n        rename(\"AREA_SQM\" = \"floor_area_sqm\", \n               \"LEASE_YRS\" = \"remaining_lease_mths\", \n               \"PRICE\"= \"resale_price\",\n               \"AGE\"= \"age\",\n               \"STOREY_ORDER\" = \"storey_order\") %>%\n        relocate(\"PRICE\") %>%\n        relocate(geometry, .after = last_col()) %>%\n      st_drop_geometry() \n\nresale_flat_full <-  filter(rs_coords_full_rds, flat_type == filter_flat_type) %>% \n        filter(month >= start_date & month <= end_date) %>%\n        select(2, 7, 11, 15:17, 19:38) %>%\n        rename(\"AREA_SQM\" = \"floor_area_sqm\", \n               \"LEASE_YRS\" = \"remaining_lease_mths\", \n               \"PRICE\"= \"resale_price\",\n               \"AGE\"= \"age\",\n               \"STOREY_ORDER\" = \"storey_order\") %>%\n        relocate(\"PRICE\") %>%\n        relocate(geometry, .after = last_col())\n\n\nresale_flat_full_perdict<- resale_flat_full %>% select(3:26)\n\n\nrs_coords_pred_rds <- write_rds(as_Spatial(tail(resale_flat_full_perdict,10)), \"data/rds/rs_coords_predict.rds\")\n\n\n\nCreating a Linear Regression Model\n\nresale_mlr1 <- lm(PRICE ~ AREA_SQM + LEASE_YRS + AGE + STOREY_ORDER + PROX_CBD + PROX_CHILDCARE + PROX_ELDERCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_TOPPRISCH + PROX_MALL + PROX_SPRMKT + PROX_CLINIC + PROX_PHARMACY + PROX_TOURISM  + PROX_LIBRARY + NUM_KNDRGTN + NUM_CHILDCARE + NUM_BUS_STOP + NUM_ISP_CLIN + NUM_REGISTERED_PHARM + NUM_LIBRARIES, resale_flat_full_nogeo)"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#moran-i-calculation",
    "href": "GWRProj/DataPreprocessing.html#moran-i-calculation",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Moran I Calculation",
    "text": "Moran I Calculation\n\nresale_res_sf <- cbind(resale_flat_full,resale_mlr1$residuals) %>%\n      rename(`MLR_RES` = resale_mlr1.residuals)\n\nresale_sp <- as_Spatial(resale_res_sf)\n\n\nCalculating Nearest Neighbour\n\nnb <- dnearneigh(coordinates(resale_sp), 0, 2500, longlat = FALSE)\n\n\n\nCalculating Neighborhood Matrix\n\nnb_lw <- nb2listw(nb, style = 'W', zero.policy = TRUE)\n\n\n\nCalculating Moran I\n\nmoran_value <- lm.morantest(resale_mlr1, nb_lw)\n\n\nmoran_value_rds <- write_rds(moran_value, \"data/rds/moran_value.rds\")\n\n\nmoran_value_rds"
  },
  {
    "objectID": "GWRProj/DataPreprocessing.html#generating-geographically-weighted-regression",
    "href": "GWRProj/DataPreprocessing.html#generating-geographically-weighted-regression",
    "title": "IS415 - Project Data Preprocessing",
    "section": "Generating Geographically Weighted Regression",
    "text": "Generating Geographically Weighted Regression\n\nCalculating Adaptive Bandwidth\n\nbw_adaptive <- bw.gwr(formula = PRICE ~ AREA_SQM + LEASE_YRS + AGE + STOREY_ORDER + PROX_CBD + PROX_CHILDCARE + PROX_ELDERCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_TOPPRISCH + PROX_MALL + PROX_SPRMKT + PROX_CLINIC + PROX_PHARMACY + PROX_TOURISM  + PROX_LIBRARY + NUM_KNDRGTN + NUM_CHILDCARE + NUM_BUS_STOP + NUM_ISP_CLIN + NUM_REGISTERED_PHARM + NUM_LIBRARIES, data=resale_sp, approach=\"CV\", kernel=\"gaussian\",\n                      adaptive=TRUE, longlat=FALSE)\n\n\n\nBuilding GWR Model\n\ngwr_adaptive <- gwr.basic(formula = PRICE ~ AREA_SQM + LEASE_YRS + AGE + STOREY_ORDER + PROX_CBD + PROX_CHILDCARE + PROX_ELDERCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_TOPPRISCH + PROX_MALL + PROX_SPRMKT + PROX_CLINIC + PROX_PHARMACY + PROX_TOURISM  + PROX_LIBRARY + NUM_KNDRGTN + NUM_CHILDCARE + NUM_BUS_STOP + NUM_ISP_CLIN + NUM_REGISTERED_PHARM + NUM_LIBRARIES,\n                      data=resale_sp, bw=9121, \n                      kernel = 'gaussian', adaptive=TRUE, longlat = FALSE)\n\n\ngwr_adaptive_rds <- write_rds(gwr_adaptive, \"data/rds/gwr_adaptive.rds\")"
  },
  {
    "objectID": "GWRProj/data/geospatial/MPSZ-2019.html",
    "href": "GWRProj/data/geospatial/MPSZ-2019.html",
    "title": "IS415 GeoSpatial Project",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415 Project - Analysis of Resale HDB Prices",
    "section": "",
    "text": "Chen Hao Xian, Tan Wen Yang and Pierre Jean Michel"
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "IS415 Project - Analysis of Resale HDB Prices",
    "section": "2 Motivation",
    "text": "2 Motivation\nWith the price of HDB resale flats seeing tremendous growth over the years, and news such as “HDB resale prices accelerate in Jan as million-dollar deals surge by 42%: SRX, 99.co” [@Yong23] or “HDB resale prices rise 2.3% in Q4, slowest increase in 2022” [@Liew23], Singaporeans face the ever-growing concern as to whether or not they are paying a fair price for their flats. Given the lack of accessibility to geographically weighted models, users may find it difficult to assess what factors impact the resale price of an HDB flat; indeed, current estimators often only consider linear relationships between dependent and independent variables and fail to include geographical predictors in their models, which may limit the ability of one regression to explain HDB resale prices; however, geographically weighted regressions provide a more sophisticated way to model spatial heterogeneity by accounting for the unique characteristics of different neighborhoods.\nDespite the advantages of geographically weighted regressions, they can be difficult for casual users without specialized skills to use effectively. Thus, our research comes in handy to give the right tools to Singaporeans as we aim to:\n\nIdentify the most significant location-specific variables that affect the resale price of HDB flats in Singapore and quantify their impact on pricing using geographically weighted regression models. By analyzing the relationship between different amenities, such as rail stations, hawker centers, preschools, malls, and mosquito hotspots, we aim to determine which factors have the most significant explanatory power on HDB resale prices and which do not. It will provide valuable insights into the most important factors that homebuyers and sellers should consider when transacting in the HDB resale market.\nDevelop a user-friendly web application that leverages geographically weighted regression models to estimate the resale value of HDB flats in Singapore for a given area. By inputting location-specific variables such as proximity to rail stations, hawker centers, preschools, malls, and mosquito hotspots, users can receive an estimated resale value for their property. It will provide users with a more accurate estimation of the value of their property, which can help them make better decisions when selling or buying an HDB flat.\nPromote transparency and reduce information asymmetry in the HDB resale market by providing an accessible and user-friendly tool for estimating resale values. By making geographically weighted regression models more accessible to the public, we hope to empower homeowners, buyers, and policymakers to make more informed decisions about the HDB resale market. It could ultimately lead to better outcomes for buyers and sellers and help policymakers make more informed decisions about housing affordability, urban planning, and education policy."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Project Proposal Summary",
    "section": "",
    "text": "Summary of our Project Proposal"
  },
  {
    "objectID": "userguide.html",
    "href": "userguide.html",
    "title": "IS415 Project - Shiny App User Guide",
    "section": "",
    "text": "While there is a link for you to access the Shiny Application, it is recommended that you run to the R application locally, as the Shiny Webpage does not provide enough resources to run all the features of the application. This is especially so if you wish to build your own model.\nThe instructions to install R and R Studio can be found here.\n\n\n\nYou can install all the relevant packages that is needed for Shiny App on R Studio. While there are quite a lot of packages to install, pacman should be prioritized to ensure the easy installation of the rest of the packages.\nTo Install the packages, Go to the tools sections, click on Install Packages. And insert the name pacman to install the correct packages.\n\n\nYou should be ready to run all the application."
  },
  {
    "objectID": "userguide.html#home-page",
    "href": "userguide.html#home-page",
    "title": "IS415 Project - Shiny App User Guide",
    "section": "4.1 Home Page",
    "text": "4.1 Home Page\n\nYou can navigate to the different sections from the navigation bar above.\nIn General, the way you want to navigate through the application is from the left to right, with the only exception being the Upload you own data."
  },
  {
    "objectID": "userguide.html#upload-file",
    "href": "userguide.html#upload-file",
    "title": "IS415 Project - Shiny App User Guide",
    "section": "4.2 Upload File",
    "text": "4.2 Upload File\nPlease read the Disclaimer on what is expected.\n\n\n\nYou can upload your pre processed file here. Once the upload is complete, you should be able to see if the uploaded table here.\n\n\n\nCongratulation now the shiny app will be using this new file for the rest of the shiny application.\n\n4.2.1 Troubleshooting\n\n4.2.1.1 I have uploaded a Table successfully but the rest of the Shiny App is not working\nYou have successfully uploaded the Table but when you enter the EDA tab you are greeted with this error. This mean that the data uploaded is not correct. You need to follow the pre processing tab closely in order to ensure that app will feed.\n\n\n\n4.2.1.2 Uploaded File but No Table is shown.\n\nThe RDS file you uploaded is not a table.\n\n\n\n4.2.2 Uploaded File Size Exceeded\n\nThe RDS File is too big. Due to the limitations of the shiny app it can only receive RDS file that is 5MB and below."
  },
  {
    "objectID": "userguide.html#eda",
    "href": "userguide.html#eda",
    "title": "IS415 Project - Shiny App User Guide",
    "section": "4.3 EDA",
    "text": "4.3 EDA\nThis section will show you the critical information of the given data set. All the plots here are dynamic and will update according to the new information given. This section is supposed to highlight more insights about the data before the model is build.\nAdjusting the filters here will have an effect on the model building."
  },
  {
    "objectID": "userguide.html#corrplot",
    "href": "userguide.html#corrplot",
    "title": "IS415 Project - Shiny App User Guide",
    "section": "4.4 CorrPlot",
    "text": "4.4 CorrPlot\nThe Correlation Plot will need to be done before we build our model. The Correlation Plot is Reactive, meaning that it changes based on the columns of the data given to it. You will need to reference this page again when building your model."
  },
  {
    "objectID": "userguide.html#multiple-linear-regression",
    "href": "userguide.html#multiple-linear-regression",
    "title": "IS415 Project - Shiny App User Guide",
    "section": "4.5 Multiple Linear Regression",
    "text": "4.5 Multiple Linear Regression\nIn This tab the multiple Linear Regression is build here. You can defined what variables you want to add to the model and what variables you want to. Test are also provided to test the accuracy of the model. With the exception of the Moran I Values, all the other variables are reactive.\n\nIf the Correlation Plot is not clear enough, highly correlated Attributes will be displayed as NA in the Linear Regression Plot.\n\n4.5.1 Computing Moran I\nTo Compute Moran I, you will need to set the variables of the Weight Matrix.\n\nPressing on Compute Moran will result in the Moran I being calculated in Real Time. Please note that this might take some time to generate a result."
  },
  {
    "objectID": "userguide.html#geographically-weighted-linear-regression",
    "href": "userguide.html#geographically-weighted-linear-regression",
    "title": "IS415 Project - Shiny App User Guide",
    "section": "4.6 Geographically Weighted Linear Regression",
    "text": "4.6 Geographically Weighted Linear Regression\nIn this tab, a pre calculated model of GWR Model is being displayed. All the Dependent variable should already have been selected in the Multiple Linear Regression Tab.\n\nIf you wish to generate your own model, all you need to do is to tune the given parameters. You can choose to generate GWR from the given parameters or calculate an adaptive bandwidth.\nNote that doing either will result in a long loading time."
  },
  {
    "objectID": "userguide.html#predicting-the-hdb-price.",
    "href": "userguide.html#predicting-the-hdb-price.",
    "title": "IS415 Project - Shiny App User Guide",
    "section": "4.7 Predicting the HDB Price.",
    "text": "4.7 Predicting the HDB Price.\nIn this tab, the user can predict the HDB Prices. You can use either of the models Multiple Linear Regression or the Geographically Weighted Regression.\nFor Multiple Linear Regression you can just input the value based on the model that you have build. Please follow order given. The values that are input should be given separated by a comma.\nFor Geographically Weighted Regression, please upload a Spatial Data frame for it to predict. However, prediction for this model will build an entirely new model to predict the values. This will take even longer to load the results out."
  },
  {
    "objectID": "userguide.html#interactive-map",
    "href": "userguide.html#interactive-map",
    "title": "IS415 Project - Shiny App User Guide",
    "section": "4.8 Interactive Map",
    "text": "4.8 Interactive Map\nYou can view an interactive map of all the data points. Find out where the HDB is and how the range of the price in this map. To prevent tmap from crashing in the shiny app, we have limited the maximum amount of points that will be displayed. Tmap is interactive and you can alter the variables"
  },
  {
    "objectID": "projectproposal.html",
    "href": "projectproposal.html",
    "title": "IS415 Project - Project Proposal",
    "section": "",
    "text": "The price of the resale HDB market has always been on the rise and have seen tremendous growth over the years. With HDB being an integral part of Singaporeans’ life, it would make sense that the affordability of the HDB is extremely important to the everyday Singaporeans. However, with new such as “HDB resale prices accelerate in Jan as million-dollar deals surge by 42%: SRX, 99.co”or “HDB resale prices rise 2.3% in Q4, slowest increase in 2022”. All this news only serve to highlight the importance of resale flat and the ever growing concern that as time passes, HDB will become more and more unaffordable to us."
  },
  {
    "objectID": "projectproposal.html#goals-of-the-project",
    "href": "projectproposal.html#goals-of-the-project",
    "title": "IS415 Project - Project Proposal",
    "section": "2 Goals of the Project",
    "text": "2 Goals of the Project\nNow that we have properly establish what our Motivation is we would like to discuss the main goals of the project.\n\nOur first goals is to find if there is any correlation between the different amenities HDB has an effect on the price of the resale flat. The data set can be found in the link provided:\n\nRail Station:It is commonly believed that the price of the resale flat is closely related to how close the HDB is to our Rail Station, as being close to the rail station means it is more convenient to travel. We would expect that the closer the rail is to the hdb, the higher the value\nHawker Centers:Hawker Centers are where almost all Singaporeans get their food from. It would make sense that we expect that the closer the Flat is to the Hawker Center the more expensive the flat will be.\nPreschool (Childcare/Kindergarten):Childcare center is especially important to parents with young children and we believe that parents are willing to pay more to have one nearby. It would make sense that we expect that the closer the Flat is to the pre-school the more expensive the flat will be.\nMalls:Hawker Centers are where almost all Singaporeans do their favorite pastime . It would make sense that we expect that the closer the Flat is to the Malls the more expensive the flat will be.\nMosquito Hotspots:We found this data set but we are not sure if there is any correlation. We would expect that since Mosquito spreads dengue fever, a high population will make the flat cheaper.\n\nOur Second Goal is to make use of the above factors to predict the value of hdb resale flat for a given area given using geographically weighted regression models.\n\nHDB Resale Data set:Contains all the relevant data about HDB Resale Flat, such as floor areas and resale price.\n\n\nWith the goals in mind, we hope that we are able to provide an interactive map of the geographical region with the price of the resale HDB and provide an reference value to the buyer on whether the asking price of the HDB is reasonable or not given the factors of the HDB Flat. This we hope will all users to make better decisions when purchasing a resale of HDB."
  },
  {
    "objectID": "projectproposal.html#relevant-related-works",
    "href": "projectproposal.html#relevant-related-works",
    "title": "IS415 Project - Project Proposal",
    "section": "3 Relevant Related Works",
    "text": "3 Relevant Related Works\n\nHDB Interactive Map: This map provides information of where the HDB is and provide an interactivity for the user to see details of the HDB. We are hoping to build something similar to this, but given that our goal is different, there will be some changes in the data shown\nHDB Resale Flat Prices: This website shows the price of the resale HDB Flat of a given area. This only shows the price of transacted HDB Flat and we are making use of data that this app uses to predict the price.\nPredict the Selling Price of HDB Resale Flats: This article by Kok Jim Meng, shows how he manages to predict the prices of HDB Flat information. We will be performing a deep dive to find out more about this.\n\n\n3.0.1 Predicting the Selling Price of HDB Resale Flats By Kok Jim Meng.\nThe first difference that I have noted is that all his code is coded in python where as we will be coding in R. The first thing he did was to identify the characteristicts he wish to dive deeper into, namely:\n\nits distance to the Central Business District (CBD)\nits distance to the nearest MRT station\nits flat size\nits floor level\nits remaining years of lease\n\nAll his data set is only from one source, from the HDB Resale Data Set. To calculate the distance to the central business district, he made use of onemap api to calculate the distance there.\nBased on his calculation, he found the following that floor size has the highest impact on the resale flat, and the distance to the nearest MRT station having the lowest strength.\nHis conclusion is that:\n\nFor every 1 metre further away from the CBD, the selling price drops by $18.12\nFor every 1 metre further away from the nearest MRT station, the selling price drops by $49.04\nFor every 1 square metre of flat size increases, the selling price rises by $4353.13\nFor every 1 remaining year lease, the selling price rises by $4079.25\nFor every rise in 1 floor, the selling price rises by $5065.95\n\nWe can take note of his conclusion in our work itself."
  },
  {
    "objectID": "projectproposal.html#approach-to-solve-the-problem",
    "href": "projectproposal.html#approach-to-solve-the-problem",
    "title": "IS415 Project - Project Proposal",
    "section": "4 Approach to Solve the Problem",
    "text": "4 Approach to Solve the Problem\nNow that we has establish our problem, here is our predicted issue\n\n4.1 Step 1: Data Wrangling (6th March to 12th March)\nThis is expected to take a large chunk of our time, as we have data set in multiple files. We will need to remove unnecessary data and also filter out all the relevant fields as not all fields is necessary in our analysis. We would need to remove all the outer islands from the map of Singapore as well.\nAfter we have cleaned up the data, we would need to create relevant fields in the maps HDB data set does not have any geospatial data, and we would need to make use of the relevant R packages to detect the coordinates of the HDB for display as well. Other data sets might not also have such data as well and we would need to fixed the issues as well.\nLastly, we would need to make the necessary computation to calculate all the relevant fields such as distance from our identified factors as well.\n\n\n4.2 Step 2: EDA (13th March to 2nd April)\nAfter we have finish wrangling the data, we would need to see how correlated the factors are with the price of the HDB. We will first visualized the relationships of the independent variables first.\nWe need to avoid using highly correlated independent variables to prevent the compromised of the quality of the model. Variables that are highly correlated with each other will need to be handled by removing one of the highly correlated models.\nWe would need to perform multiple steps in order to ensure that the regression model is the most accurate, namely (all this is reference from R for Geospatial Data Science and Analytics by Dr Kam Tin Seong):\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\n\n\n4.3 Step 3: Geographically Weighted Regression Models (2nd April to 16th April)\nAfter we have perform our EDA, and selected all the proper variable we can finally build a proper regression model. As we have already perform all the necessary tuning of the model during the EDA steps, we would need to build the model and check out the initial generation of data. We would need to interpret the data into a easier to understand format as well. Once we are done with it, we can start the make the model interactive.\nWe will need to convert it into a shiny web app, and allow users to modify the variable so that they may get the prediction based on their selected variables.\n\n\n4.4 Time Line"
  },
  {
    "objectID": "projectproposal.html#story-boarding",
    "href": "projectproposal.html#story-boarding",
    "title": "IS415 Project - Project Proposal",
    "section": "5 Story Boarding",
    "text": "5 Story Boarding\n\n5.1 HOME PAGE\n\n\n\n5.2 EDA Page (Visualize EDA Data)\n\n\n\n5.3 Prediction Page (Shows the prediction)"
  }
]